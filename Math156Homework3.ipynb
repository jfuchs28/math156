{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jordyn Fuchs\n",
    "\n",
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "\n",
    "Train a binary logistic regression model using mini-batch SGD. Use the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sigmoid function\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# create cross-entropy loss function\n",
    "\n",
    "def crossentropy(t, y):\n",
    "    epsilon = 1e-5\n",
    "    return (-1 / len(t)) * (np.sum( t * np.log(y + epsilon) + (1 - t) * np.log( 1 - y + epsilon ) ))\n",
    "\n",
    "# create logistic regression function\n",
    "\n",
    "def logisticregression(X, t, batchsize = 64, learningrate = 0.01, iterations = 100):\n",
    "    row, col = X.shape\n",
    "    w = np.zeros(col)\n",
    "\n",
    "    for i in range(0, row, batchsize):\n",
    "        X_sub = X[i:i+batchsize]\n",
    "        t_sub = t[i:i+batchsize]\n",
    "\n",
    "        y = sigmoid(np.dot(X_sub, w))\n",
    "        gradient = np.dot((y - t_sub), X_sub) * (1/batchsize)\n",
    "\n",
    "        w = w - (gradient * learningrate)\n",
    "\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4a\n",
    "\n",
    "Download Wisconsin Breast Cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 17, 'name': 'Breast Cancer Wisconsin (Diagnostic)', 'repository_url': 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'data_url': 'https://archive.ics.uci.edu/static/public/17/data.csv', 'abstract': 'Diagnostic Wisconsin Breast Cancer Database.', 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 569, 'num_features': 30, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['Diagnosis'], 'index_col': ['ID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1993, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5DW2B', 'creators': ['William Wolberg', 'Olvi Mangasarian', 'Nick Street', 'W. Street'], 'intro_paper': {'ID': 230, 'type': 'NATIVE', 'title': 'Nuclear feature extraction for breast tumor diagnosis', 'authors': 'W. Street, W. Wolberg, O. Mangasarian', 'venue': 'Electronic imaging', 'year': 1993, 'journal': None, 'DOI': '10.1117/12.148698', 'URL': 'https://www.semanticscholar.org/paper/53f0fbb425bc14468eb3bf96b2e1d41ba8087f36', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. A few of the images can be found at http://www.cs.wisc.edu/~street/images/\\r\\n\\r\\nSeparating plane described above was obtained using Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree Construction Via Linear Programming.\" Proceedings of the 4th Midwest Artificial Intelligence and Cognitive Science Society, pp. 97-101, 1992], a classification method which uses linear programming to construct a decision tree.  Relevant features were selected using an exhaustive search in the space of 1-4 features and 1-3 separating planes.\\r\\n\\r\\nThe actual linear program used to obtain the separating plane in the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\\r\\n\\r\\nThis database is also available through the UW CS ftp server:\\r\\nftp ftp.cs.wisc.edu\\r\\ncd math-prog/cpo-dataset/machine-learn/WDBC/', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '1) ID number\\r\\n2) Diagnosis (M = malignant, B = benign)\\r\\n3-32)\\r\\n\\r\\nTen real-valued features are computed for each cell nucleus:\\r\\n\\r\\n\\ta) radius (mean of distances from center to points on the perimeter)\\r\\n\\tb) texture (standard deviation of gray-scale values)\\r\\n\\tc) perimeter\\r\\n\\td) area\\r\\n\\te) smoothness (local variation in radius lengths)\\r\\n\\tf) compactness (perimeter^2 / area - 1.0)\\r\\n\\tg) concavity (severity of concave portions of the contour)\\r\\n\\th) concave points (number of concave portions of the contour)\\r\\n\\ti) symmetry \\r\\n\\tj) fractal dimension (\"coastline approximation\" - 1)', 'citation': None}}\n",
      "                  name     role         type demographic description units  \\\n",
      "0                   ID       ID  Categorical        None        None  None   \n",
      "1            Diagnosis   Target  Categorical        None        None  None   \n",
      "2              radius1  Feature   Continuous        None        None  None   \n",
      "3             texture1  Feature   Continuous        None        None  None   \n",
      "4           perimeter1  Feature   Continuous        None        None  None   \n",
      "5                area1  Feature   Continuous        None        None  None   \n",
      "6          smoothness1  Feature   Continuous        None        None  None   \n",
      "7         compactness1  Feature   Continuous        None        None  None   \n",
      "8           concavity1  Feature   Continuous        None        None  None   \n",
      "9      concave_points1  Feature   Continuous        None        None  None   \n",
      "10           symmetry1  Feature   Continuous        None        None  None   \n",
      "11  fractal_dimension1  Feature   Continuous        None        None  None   \n",
      "12             radius2  Feature   Continuous        None        None  None   \n",
      "13            texture2  Feature   Continuous        None        None  None   \n",
      "14          perimeter2  Feature   Continuous        None        None  None   \n",
      "15               area2  Feature   Continuous        None        None  None   \n",
      "16         smoothness2  Feature   Continuous        None        None  None   \n",
      "17        compactness2  Feature   Continuous        None        None  None   \n",
      "18          concavity2  Feature   Continuous        None        None  None   \n",
      "19     concave_points2  Feature   Continuous        None        None  None   \n",
      "20           symmetry2  Feature   Continuous        None        None  None   \n",
      "21  fractal_dimension2  Feature   Continuous        None        None  None   \n",
      "22             radius3  Feature   Continuous        None        None  None   \n",
      "23            texture3  Feature   Continuous        None        None  None   \n",
      "24          perimeter3  Feature   Continuous        None        None  None   \n",
      "25               area3  Feature   Continuous        None        None  None   \n",
      "26         smoothness3  Feature   Continuous        None        None  None   \n",
      "27        compactness3  Feature   Continuous        None        None  None   \n",
      "28          concavity3  Feature   Continuous        None        None  None   \n",
      "29     concave_points3  Feature   Continuous        None        None  None   \n",
      "30           symmetry3  Feature   Continuous        None        None  None   \n",
      "31  fractal_dimension3  Feature   Continuous        None        None  None   \n",
      "\n",
      "   missing_values  \n",
      "0              no  \n",
      "1              no  \n",
      "2              no  \n",
      "3              no  \n",
      "4              no  \n",
      "5              no  \n",
      "6              no  \n",
      "7              no  \n",
      "8              no  \n",
      "9              no  \n",
      "10             no  \n",
      "11             no  \n",
      "12             no  \n",
      "13             no  \n",
      "14             no  \n",
      "15             no  \n",
      "16             no  \n",
      "17             no  \n",
      "18             no  \n",
      "19             no  \n",
      "20             no  \n",
      "21             no  \n",
      "22             no  \n",
      "23             no  \n",
      "24             no  \n",
      "25             no  \n",
      "26             no  \n",
      "27             no  \n",
      "28             no  \n",
      "29             no  \n",
      "30             no  \n",
      "31             no  \n"
     ]
    }
   ],
   "source": [
    "# read in dataset\n",
    "\n",
    "#!pip install ucimlrepo\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(breast_cancer_wisconsin_diagnostic.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4b\n",
    "Split data into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scikit-learn to split data into train, validation, and test sets\n",
    "# 80% train, 10% validation, 10% test\n",
    "\n",
    "X_train, X_test_full, y_train, y_test_full = train_test_split(X, y, \n",
    "test_size=0.2, random_state = 28)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test_full, y_test_full, \n",
    "test_size = 0.5, random_state = 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4c\n",
    "Report the size of each class in your training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnosis\n",
      "B            284\n",
      "M            171\n",
      "Name: count, dtype: int64\n",
      "Diagnosis\n",
      "B            40\n",
      "M            17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_val.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the training set, there are 284 benign values and 171 malignant values. In the validation set, there are 40 benign values and 17 malignant values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4d\n",
    "Train a binary logistic regression model using your implementation from problem 3. Initialize the model weights randomly, sampling from a standard Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/lg/rf0x35w16dzdlc87h7c337g40000gn/T/ipykernel_16890/4193081640.py\", line 3, in <module>\n",
      "    w = logisticregression(X_train, y_train, batchsize = 16, learningrate = 0.1, iterations = 100)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/lg/rf0x35w16dzdlc87h7c337g40000gn/T/ipykernel_16890/2902290470.py\", line 23, in logisticregression\n",
      "    gradient = np.dot((y - t_sub), X_sub) * (1/batchsize)\n",
      "                       ~~^~~~~~~\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/generic.py\", line 2102, in __array_ufunc__\n",
      "    return arraylike.array_ufunc(self, ufunc, method, *inputs, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/arraylike.py\", line 273, in array_ufunc\n",
      "    result = maybe_dispatch_ufunc_to_dunder_op(self, ufunc, method, *inputs, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"ops_dispatch.pyx\", line 113, in pandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/arraylike.py\", line 198, in __rsub__\n",
      "    return self._arith_method(other, roperator.rsub)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/frame.py\", line 7641, in _arith_method\n",
      "    self, other = self._align_for_op(other, axis, flex=True, level=None)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/frame.py\", line 7872, in _align_for_op\n",
      "    right = to_series(right)\n",
      "            ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/pandas/core/frame.py\", line 7864, in to_series\n",
      "    raise ValueError(\n",
      "ValueError: Unable to coerce to Series, length must be 1: given 16\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1155, in get_records\n",
      "    FrameInfo(\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/inspect.py\", line 1244, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "                  ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/inspect.py\", line 1081, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "# use logisticregression function created in problem 3\n",
    "\n",
    "w = logisticregression(X_train, y_train, batchsize = 16, learningrate = 0.1, iterations = 100)\n",
    "print(w)\n",
    "\n",
    "w2 = logisticregression(X_train, y_train, batchsize = 32, learningrate = 0.01, iterations = 100)\n",
    "print(w2)\n",
    "\n",
    "w3 = logisticregression(X_train, y_train, batchsize = 64, learningrate = 0.001, iterations = 100)\n",
    "print(w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jordynfuchs/anaconda3/envs/pic16b/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=28)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "ypred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4e\n",
    "Use the trained model to report the performance on the model test set. Use accuracy, precision, recall, and F1-score for evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# get y predictions using test set\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m y_prob \u001b[39m=\u001b[39m sigmoid(np\u001b[39m.\u001b[39mdot(X_test, w))\n\u001b[1;32m      4\u001b[0m y_pred \u001b[39m=\u001b[39m (y_prob \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "# get y predictions using test set\n",
    "\n",
    "y_prob = sigmoid(np.dot(X_test, w))\n",
    "y_pred = (y_prob >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix:  [[30  3]\n",
      " [ 1 23]]\n",
      "accuracy:  0.9298245614035088\n",
      "precision:  0.8846153846153846\n",
      "recall:  0.9583333333333334\n",
      "f1:  0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, ypred)\n",
    "print(\"confusion matrix: \", confusion)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, ypred)\n",
    "print(\"accuracy: \", accuracy)\n",
    "\n",
    "# precision\n",
    "precision = 23/(23+3)\n",
    "print(\"precision: \", precision)\n",
    "\n",
    "# recall\n",
    "recall = precision = 23/(23+1)\n",
    "print(\"recall: \", recall)\n",
    "\n",
    "# f1 score\n",
    "print(\"f1: \", ((2*precision*recall/(precision + recall))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4f\n",
    "Summarize your findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a relatively high accuracy of 92.98%. There is a higher recall (95.83%) than precision (88.46%), meaning that it is effective at identifying the positive cases but it is also resulting in some false positive values. However, both metrics are still relatively high indicating strong results. Finally, the model has a high f1 score of 95.83%, which indicates a strong balance between precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.7 ('pic16b')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "85db1b375aba9bf91b2ae2177746c8cb6a4122f62341acada130d5d82bb39905"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
